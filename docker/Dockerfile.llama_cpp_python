FROM cuda_image

COPY llama_cpp_python/llama_config.json .

RUN CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip3 install llama-cpp-python[server]